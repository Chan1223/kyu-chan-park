{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling,\n",
    "독립변수 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Experience  Income\n",
       "0   50       1          15     180\n",
       "1   29       1           5     163\n",
       "2   36       1           6     134\n",
       "3   34       2           4     132\n",
       "4   46       1           9     188"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_np) #데이터를 random하게 다시 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속변수와 독립변수 데이터 분리하기\n",
    "y = data_np[:,-1]\n",
    "X = data_np[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30,  2,  2],\n",
       "       [31,  2,  4],\n",
       "       [23,  2,  2],\n",
       "       [50,  2, 21],\n",
       "       [32,  1,  3],\n",
       "       [46,  1, 13],\n",
       "       [41,  2, 15],\n",
       "       [47,  2, 21],\n",
       "       [57,  2, 29],\n",
       "       [58,  2, 29],\n",
       "       [55,  1, 26],\n",
       "       [28,  2,  2],\n",
       "       [24,  2,  2],\n",
       "       [50,  1, 20],\n",
       "       [38,  1, 11],\n",
       "       [30,  1,  2],\n",
       "       [46,  1,  9],\n",
       "       [33,  1,  3],\n",
       "       [40,  1, 13],\n",
       "       [28,  1,  1],\n",
       "       [59,  2, 33],\n",
       "       [26,  1,  1],\n",
       "       [28,  2,  2],\n",
       "       [57,  2, 29],\n",
       "       [55,  2, 25],\n",
       "       [30,  2,  1],\n",
       "       [26,  2,  8],\n",
       "       [52,  2, 27],\n",
       "       [23,  1,  5],\n",
       "       [51,  2, 26]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = scaler.fit_transform(X_train) # 학습데이터 존재하는 평균과 표준편차를 얻어냄\n",
    "X_test_std = scaler.transform(X_test) # 학습데이터에서 얻은 값을 평가데이터에 적용시킴, fit 을 뺀 transform만 사용.\n",
    "# -> x_test에 fit_transform을 해도 에러는 안남. 근데 그렇게 되면 따로따로 scaling을 하는 꼴이기 때문에 옳지 못함\n",
    "\n",
    "\n",
    "# 평가데이터는 학습데이터에 얻어진 평균과 표준 편차를 가지고 평가 데이터에 존재하는 독립변수를 표준화시킴.\n",
    "# 평가데이터는 학습의 결과로 도출된 모형의 성능을 평가하기 위해 사용함.\n",
    "# 학습 / 평가 데이터의 표준화를 따로따로 하면 표준화 이후 값이 달라지는 경우가 생김. -> 모형의 제대로된 평가가 불가능\n",
    "# 그렇기 때문에 학습 데이터로 scaling된 정보를 이용해 평가 데이터도 scaling함\n",
    "\n",
    "# 전체 데이터를 가지고 feature scaling을 하면 안되나??\n",
    "# -> 평가 데이터는 학습에 사용되면 안됨. 전체 데이터로 표준화를 하게 되면 평가데이터로 사용되는 정보가 반영되어버림.\n",
    "# -> 학습 데이터와 연관되기 때문에 모형의 성능이 훨씬 좋은 것처럼 나오게 됨(이걸 overfitting이라고 이해할 수 있나?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36752833, -0.89155583, -0.35581573],\n",
       "       [ 1.18919996,  1.12163475,  1.12088988],\n",
       "       [-0.4494614 ,  1.12163475, -0.84805094],\n",
       "       [ 1.10726689, -0.89155583,  1.21933692],\n",
       "       [ 1.18919996, -0.89155583,  1.21933692],\n",
       "       [ 0.77953462,  1.12163475,  0.33331355],\n",
       "       [-0.94105981, -0.89155583, -0.65115686],\n",
       "       [-0.03979606,  1.12163475, -0.15892165],\n",
       "       [ 1.02533382,  1.12163475,  0.9239958 ],\n",
       "       [ 0.45180235, -0.89155583,  0.43176059],\n",
       "       [ 1.51693223, -0.89155583,  1.81001917],\n",
       "       [-0.77719368, -0.89155583, -0.94649798],\n",
       "       [ 0.86146769,  1.12163475,  1.02244284],\n",
       "       [-0.12172913,  1.12163475, -0.15892165],\n",
       "       [-0.61332754, -0.89155583, -0.55270982],\n",
       "       [-1.18685902,  1.12163475, -1.04494502],\n",
       "       [ 1.68079837, -0.89155583,  2.10536029],\n",
       "       [ 1.68079837, -0.89155583,  2.10536029],\n",
       "       [-1.02299288,  1.12163475, -1.04494502],\n",
       "       [-1.43265822,  1.12163475, -1.04494502],\n",
       "       [-0.36752833,  1.12163475, -0.7496039 ],\n",
       "       [-1.18685902,  1.12163475, -0.94649798],\n",
       "       [-0.4494614 , -0.89155583, -0.55270982],\n",
       "       [ 0.45180235, -0.89155583, -0.15892165],\n",
       "       [ 1.76273144, -0.89155583,  1.31778396],\n",
       "       [ 1.76273144,  1.12163475,  2.00691325],\n",
       "       [ 0.94340076, -0.89155583,  0.9239958 ],\n",
       "       [-1.02299288,  1.12163475, -0.94649798],\n",
       "       [-1.43265822,  1.12163475, -1.04494502],\n",
       "       [ 0.61566848,  1.12163475,  0.72710172],\n",
       "       [ 0.61566848, -0.89155583,  0.03797243],\n",
       "       [-1.35072515, -0.89155583, -1.04494502],\n",
       "       [-0.4494614 , -0.89155583, -0.45426278],\n",
       "       [-1.18685902,  1.12163475, -1.04494502],\n",
       "       [-0.85912674, -0.89155583, -0.94649798],\n",
       "       [ 0.04213701, -0.89155583, -0.15892165],\n",
       "       [-1.26879208,  1.12163475, -0.84805094],\n",
       "       [-1.26879208, -0.89155583, -1.04494502],\n",
       "       [ 0.94340076, -0.89155583,  0.33331355],\n",
       "       [-0.12172913,  1.12163475, -0.06047461],\n",
       "       [-1.26879208,  1.12163475, -1.04494502],\n",
       "       [-0.28559527, -0.89155583, -0.65115686],\n",
       "       [ 1.3530661 , -0.89155583,  1.81001917],\n",
       "       [ 0.69760155,  1.12163475,  0.62865468],\n",
       "       [-1.35072515,  1.12163475, -1.04494502],\n",
       "       [-1.10492595,  1.12163475, -1.14339206],\n",
       "       [-0.53139447, -0.89155583, -0.84805094],\n",
       "       [ 1.18919996,  1.12163475,  1.41623101],\n",
       "       [-0.4494614 , -0.89155583, -0.84805094],\n",
       "       [ 1.51693223,  1.12163475,  1.61312509],\n",
       "       [-0.77719368, -0.89155583, -0.65115686],\n",
       "       [-0.85912674,  1.12163475, -0.84805094],\n",
       "       [-1.35072515, -0.89155583, -1.04494502],\n",
       "       [-1.35072515, -0.89155583, -1.04494502],\n",
       "       [ 1.02533382,  1.12163475,  0.53020764],\n",
       "       [ 0.77953462, -0.89155583, -0.45426278],\n",
       "       [-0.12172913, -0.89155583, -0.06047461],\n",
       "       [ 0.61566848,  1.12163475,  0.72710172],\n",
       "       [-1.02299288,  1.12163475, -0.94649798],\n",
       "       [ 1.51693223, -0.89155583,  1.90846621],\n",
       "       [-1.18685902, -0.89155583, -0.65115686],\n",
       "       [ 0.12407007, -0.89155583, -0.25736869],\n",
       "       [-0.2036622 , -0.89155583, -0.06047461],\n",
       "       [ 0.36986928,  1.12163475,  0.53020764],\n",
       "       [ 0.04213701, -0.89155583, -0.55270982],\n",
       "       [ 0.61566848, -0.89155583,  0.72710172],\n",
       "       [ 1.51693223, -0.89155583,  1.81001917],\n",
       "       [ 0.86146769,  1.12163475,  1.02244284],\n",
       "       [-0.2036622 , -0.89155583, -0.55270982],\n",
       "       [-0.85912674, -0.89155583, -0.84805094]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23319728, -1.02899151, -0.57455739],\n",
       "       [ 1.46383242,  0.97182532,  1.51227842],\n",
       "       [-1.44536135,  0.97182532, -1.04883826],\n",
       "       [ 1.6254543 , -1.02899151,  1.98655929],\n",
       "       [-0.39481915,  0.97182532, -0.76426974],\n",
       "       [ 0.65572304,  0.97182532,  0.56371669],\n",
       "       [-0.47563009, -1.02899151, -0.47970122],\n",
       "       [-0.96049572, -1.02899151, -0.66941357],\n",
       "       [-1.20292854,  0.97182532, -1.04883826],\n",
       "       [ 1.6254543 , -1.02899151,  1.98655929],\n",
       "       [-0.0715754 ,  0.97182532, -0.1951327 ],\n",
       "       [-0.31400822, -1.02899151, -0.66941357],\n",
       "       [-0.0715754 , -1.02899151, -0.10027653],\n",
       "       [-1.44536135,  0.97182532, -1.04883826],\n",
       "       [ 0.00923554, -1.02899151, -0.1951327 ],\n",
       "       [ 1.46383242, -1.02899151,  1.70199077],\n",
       "       [ 1.14058867, -1.02899151,  1.13285373],\n",
       "       [-0.63725197,  0.97182532, -0.76426974],\n",
       "       [ 0.5749121 , -1.02899151, -0.00542035],\n",
       "       [ 0.89815585, -1.02899151,  0.75342904],\n",
       "       [ 0.00923554, -1.02899151, -0.57455739],\n",
       "       [-0.87968478,  0.97182532, -0.95398209],\n",
       "       [-1.36455041, -1.02899151, -1.04883826],\n",
       "       [ 0.89815585,  0.97182532,  0.84828521],\n",
       "       [ 0.09004647, -1.02899151,  0.08943582],\n",
       "       [-0.47563009, -1.02899151, -0.57455739],\n",
       "       [ 0.65572304,  0.97182532,  0.84828521],\n",
       "       [-1.28373947, -1.02899151, -1.04883826],\n",
       "       [-0.87968478,  0.97182532, -0.85912591],\n",
       "       [ 0.97896679,  0.97182532,  0.46886051]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_std = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_std.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5981380889022867"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_std.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "# min-max 스케일링은 학습 데이터를 통해 0-1 사이의 값을 만들지만,\n",
    "# 평가데이터의 경우 학습데이터에서 얻어진 정보를 이용해 평가데이터의 독립변수를 minmax 시키기 때문에\n",
    "# 평가데이터는 0-1 사이 안에 있지 않을 수 있다. (벗어날 수 있다. 근데 그래도 상관 없다)\n",
    "# 평가 데이터가 갖는 값의 범위가 학습데이터와 동일하지 않을 경우 0-1을 벗어날 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling 이후 , 독립변수 수가 적거나 데이터가 너무 적을 경우, 어떤 데이터를 다루느냐에 따라 scaling을 사용 안하는것이 값이 더 잘 나올수도 있다.\n",
    "-> 최종적으로 모형의 성능이 좋게 나오는 방법을 선택하는것이 답이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
    "X_test_minmax = scaler_minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36842105,  0.        ,  0.18181818],\n",
       "       [ 0.92105263,  1.        ,  0.84848485],\n",
       "       [-0.02631579,  1.        ,  0.03030303],\n",
       "       [ 0.97368421,  0.        ,  1.        ],\n",
       "       [ 0.31578947,  1.        ,  0.12121212],\n",
       "       [ 0.65789474,  1.        ,  0.54545455],\n",
       "       [ 0.28947368,  0.        ,  0.21212121],\n",
       "       [ 0.13157895,  0.        ,  0.15151515],\n",
       "       [ 0.05263158,  1.        ,  0.03030303],\n",
       "       [ 0.97368421,  0.        ,  1.        ],\n",
       "       [ 0.42105263,  1.        ,  0.3030303 ],\n",
       "       [ 0.34210526,  0.        ,  0.15151515],\n",
       "       [ 0.42105263,  0.        ,  0.33333333],\n",
       "       [-0.02631579,  1.        ,  0.03030303],\n",
       "       [ 0.44736842,  0.        ,  0.3030303 ],\n",
       "       [ 0.92105263,  0.        ,  0.90909091],\n",
       "       [ 0.81578947,  0.        ,  0.72727273],\n",
       "       [ 0.23684211,  1.        ,  0.12121212],\n",
       "       [ 0.63157895,  0.        ,  0.36363636],\n",
       "       [ 0.73684211,  0.        ,  0.60606061],\n",
       "       [ 0.44736842,  0.        ,  0.18181818],\n",
       "       [ 0.15789474,  1.        ,  0.06060606],\n",
       "       [ 0.        ,  0.        ,  0.03030303],\n",
       "       [ 0.73684211,  1.        ,  0.63636364],\n",
       "       [ 0.47368421,  0.        ,  0.39393939],\n",
       "       [ 0.28947368,  0.        ,  0.18181818],\n",
       "       [ 0.65789474,  1.        ,  0.63636364],\n",
       "       [ 0.02631579,  0.        ,  0.03030303],\n",
       "       [ 0.15789474,  1.        ,  0.09090909],\n",
       "       [ 0.76315789,  1.        ,  0.51515152]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_minmax = LinearRegression()\n",
    "model_minmax.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5981380889022867"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_minmax.score(X_test_minmax, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
